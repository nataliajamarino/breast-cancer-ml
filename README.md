# C√¢ncer de Mama ML ‚Äî Projeto Tech Challenge Fase 2

**Otimiza√ß√£o de Modelos de Diagn√≥stico com Algoritmos Gen√©ticos e LLMs**

Este projeto implementa um sistema completo de machine learning para diagn√≥stico de c√¢ncer de mama, com otimiza√ß√£o de hiperpar√¢metros usando algoritmos gen√©ticos e explica√ß√µes autom√°ticas geradas por LLMs (Large Language Models).

## üéØ Objetivos do Projeto

- **Fase 1**: Classifica√ß√£o bin√°ria maligno vs. benigno com alto recall
- **Fase 2**: Otimiza√ß√£o com algoritmos gen√©ticos + explica√ß√µes com LLMs
- **Aplica√ß√£o**: Ferramenta de apoio ao diagn√≥stico m√©dico

## üöÄ In√≠cio R√°pido

### Instala√ß√£o

```bash
# 1. Clone o reposit√≥rio
git clone <repository-url>
cd breast-cancer-ml

# 2. Crie um ambiente virtual
python -m venv .venv
source .venv/bin/activate  # Windows: .venv\Scripts\activate

# 3. Instale as depend√™ncias
pip install -r requirements.txt

# 4. Execute tudo
bash scripts/run_all.sh
```

### Executar Otimiza√ß√£o Gen√©tica

```bash
# Executar experimentos de otimiza√ß√£o
python src/ga_optimizer.py

# Ou executar notebook interativo
jupyter notebook notebooks/02_genetic_optimization.ipynb
```

### Executar Explica√ß√µes com LLM

```bash
# Para usar OpenAI (opcional)
export OPENAI_API_KEY="sua-chave-aqui"

# Executar demonstra√ß√£o
python src/llm_explainer.py

# Ou executar notebook interativo
jupyter notebook notebooks/03_llm_interpretation.ipynb
```

## üìÅ Estrutura do Projeto

```
breast-cancer-ml/
‚îú‚îÄ data/                     # Dataset (sklearn ou CSV pr√≥prio)
‚îú‚îÄ notebooks/                # Notebooks interativos
‚îÇ  ‚îú‚îÄ 01_eda_shap_fix.ipynb # EDA e SHAP analysis
‚îÇ  ‚îú‚îÄ 02_genetic_optimization.ipynb # Otimiza√ß√£o gen√©tica
‚îÇ  ‚îî‚îÄ 03_llm_interpretation.ipynb   # Explica√ß√µes com LLM
‚îú‚îÄ src/
‚îÇ  ‚îú‚îÄ features.py            # Carregamento e splits dos dados
‚îÇ  ‚îú‚îÄ models_tabular.py      # Configura√ß√µes dos modelos
‚îÇ  ‚îú‚îÄ train_tabular.py       # Treino com CV + calibra√ß√£o
‚îÇ  ‚îú‚îÄ evaluate.py            # Avalia√ß√£o e m√©tricas
‚îÇ  ‚îú‚îÄ ga_optimizer.py        # ‚≠ê Algoritmo gen√©tico
‚îÇ  ‚îú‚îÄ llm_explainer.py       # ‚≠ê Explica√ß√µes com LLM
‚îÇ  ‚îî‚îÄ utils.py               # Utilit√°rios
‚îú‚îÄ models/                   # Modelos treinados (.joblib)
‚îú‚îÄ reports/                  # Resultados e relat√≥rios
‚îÇ  ‚îú‚îÄ figures/               # Gr√°ficos e visualiza√ß√µes
‚îÇ  ‚îú‚îÄ ga_*.json             # ‚≠ê Resultados da otimiza√ß√£o gen√©tica
‚îÇ  ‚îú‚îÄ *_explanation.txt     # ‚≠ê Explica√ß√µes geradas por LLM
‚îÇ  ‚îî‚îÄ patient_reports.json  # ‚≠ê Relat√≥rios para pacientes
‚îú‚îÄ tests/                    # ‚≠ê Testes automatizados
‚îÇ  ‚îî‚îÄ test_ga_optimizer.py   # Testes do GA e LLM
‚îú‚îÄ scripts/
‚îÇ  ‚îî‚îÄ run_all.sh             # Executor completo
‚îú‚îÄ requirements.txt          # ‚≠ê Depend√™ncias atualizadas
‚îú‚îÄ pytest.ini              # ‚≠ê Configura√ß√£o de testes
‚îú‚îÄ Dockerfile
‚îî‚îÄ README.md
```

## üß¨ Algoritmos Gen√©ticos

### Como Funciona

O algoritmo gen√©tico otimiza hiperpar√¢metros atrav√©s de:

1. **Popula√ß√£o Inicial**: Conjuntos aleat√≥rios de hiperpar√¢metros
2. **Avalia√ß√£o**: Fitness baseado em accuracy + recall + F1-score
3. **Sele√ß√£o**: Torneio para escolher melhores indiv√≠duos
4. **Cruzamento**: Combina√ß√£o de hiperpar√¢metros entre indiv√≠duos
5. **Muta√ß√£o**: Altera√ß√µes aleat√≥rias para explora√ß√£o
6. **Evolu√ß√£o**: Repetir por N gera√ß√µes

### Modelos Suportados

- **Random Forest**: n_estimators, max_depth, min_samples_split, etc.
- **XGBoost**: learning_rate, max_depth, subsample, regulariza√ß√£o
- **LightGBM**: learning_rate, num_leaves, feature_fraction
- **SVM**: C, gamma, kernel
- **Logistic Regression**: C, penalty, solver

### Experimentos Configurados

1. **Conservative**: Popula√ß√£o=30, Gera√ß√µes=20 (execu√ß√£o r√°pida)
2. **Standard**: Popula√ß√£o=50, Gera√ß√µes=30 (balanceado)
3. **Aggressive**: Popula√ß√£o=80, Gera√ß√µes=50 (busca extensiva)

### Exemplo de Uso

```python
from src.ga_optimizer import GeneticOptimizer

# Criar otimizador
optimizer = GeneticOptimizer(
    model_type='random_forest',
    population_size=50,
    generations=30,
    crossover_prob=0.7,
    mutation_prob=0.3
)

# Executar otimiza√ß√£o
result = optimizer.optimize(X_train, y_train)

print(f"Melhor fitness: {result['best_fitness']:.4f}")
print(f"Melhores par√¢metros: {result['best_params']}")
```

## ü§ñ LLMs para Explica√ß√µes

### Funcionalidades

1. **Explica√ß√µes de Diagn√≥stico**: Interpreta predi√ß√µes individuais
2. **An√°lise de Performance**: Explica m√©tricas do modelo
3. **Compara√ß√£o de Modelos**: Compara diferentes algoritmos
4. **Relat√≥rios para Pacientes**: Linguagem acess√≠vel

### Providers Suportados

- **OpenAI GPT**: Melhor qualidade (requer API key)
- **HuggingFace**: Modelos locais (sem internet)
- **Simulador**: Respostas pr√©-definidas (demonstra√ß√£o)

### Configura√ß√£o OpenAI

```bash
# Definir chave da API
export OPENAI_API_KEY="sua-chave-openai"

# Ou no c√≥digo
explainer = LLMExplainer(
    provider="openai",
    model_name="gpt-3.5-turbo",
    api_key="sua-chave"
)
```

### Exemplo de Uso

```python
from src.llm_explainer import LLMExplainer

# Criar explainer
explainer = LLMExplainer(provider="openai")

# Explicar diagn√≥stico
explanation = explainer.generate_explanation(
    prediction=1,  # Maligno
    probability=0.89,
    feature_importance={'texture_mean': 0.23, 'area_mean': 0.19},
    model_metrics={'accuracy': 0.95, 'recall': 0.97}
)

print(explanation)
```

## üìä Resultados e Compara√ß√µes

### M√©tricas Priorizadas

- **Recall (Sensibilidade)**: ‚â• 0.95 (detectar todos os casos malignos)
- **Precision**: Minimizar falsos positivos
- **F1-Score**: Equil√≠brio entre precision e recall
- **Accuracy**: Performance geral

### Melhorias Esperadas

- **Baseline**: Modelos com hiperpar√¢metros padr√£o
- **GA Otimizado**: +2-5% de melhoria nas m√©tricas
- **Explicabilidade**: Confian√ßa e transpar√™ncia aumentadas

### Visualiza√ß√µes Geradas

- Converg√™ncia do algoritmo gen√©tico
- Compara√ß√£o de fitness entre experimentos
- Gr√°ficos de performance baseline vs otimizado
- Import√¢ncia das features

## üß™ Testes Automatizados

```bash
# Executar todos os testes
pytest

# Testes espec√≠ficos
pytest tests/test_ga_optimizer.py -v

# Testes com cobertura
pytest --cov=src tests/
```

### Testes Implementados

- **GeneticOptimizer**: Inicializa√ß√£o, otimiza√ß√£o, converg√™ncia
- **LLMExplainer**: Gera√ß√£o de explica√ß√µes, providers
- **Integra√ß√£o**: GA + LLM workflow completo
- **Valida√ß√£o**: Dados, modelos, resultados

## üê≥ Docker

```bash
# Build da imagem
docker build -t breast-cancer-ml .

# Executar container
docker run --rm -it -v $PWD:/app breast-cancer-ml

# Com GPU (se dispon√≠vel)
docker run --gpus all --rm -it -v $PWD:/app breast-cancer-ml
```

## üìà Como Executar Cada Notebook

### 1. EDA e SHAP Analysis
```bash
jupyter notebook notebooks/01_eda_shap_fix.ipynb
```
- An√°lise explorat√≥ria dos dados
- Visualiza√ß√£o das features
- SHAP values para interpretabilidade

### 2. Otimiza√ß√£o Gen√©tica
```bash
jupyter notebook notebooks/02_genetic_optimization.ipynb
```
- Execu√ß√£o dos 3 experimentos de GA
- Visualiza√ß√£o da converg√™ncia
- Compara√ß√£o baseline vs otimizado
- **Tempo estimado**: 15-30 minutos

### 3. Interpreta√ß√£o com LLM
```bash
jupyter notebook notebooks/03_llm_interpretation.ipynb
```
- Configura√ß√£o do LLM (OpenAI ou simulador)
- Explica√ß√µes de casos individuais
- Relat√≥rios para pacientes e m√©dicos
- **Tempo estimado**: 5-10 minutos

## üìã Roteiro para V√≠deo de Demonstra√ß√£o (15 min)

### Parte 1: Introdu√ß√£o (2 min)
- Apresentar o problema: diagn√≥stico de c√¢ncer de mama
- Mostrar dataset e m√©tricas baseline
- Explicar objetivos da Fase 2

### Parte 2: Algoritmo Gen√©tico (6 min)
- Abrir notebook `02_genetic_optimization.ipynb`
- Executar otimiza√ß√£o r√°pida (Conservative)
- Mostrar evolu√ß√£o do fitness
- Comparar resultados: baseline vs otimizado
- Destacar melhorias nas m√©tricas

### Parte 3: Explica√ß√µes com LLM (5 min)
- Abrir notebook `03_llm_interpretation.ipynb`
- Mostrar explica√ß√£o de caso maligno
- Mostrar explica√ß√£o de caso benigno
- Demonstrar relat√≥rio para paciente
- Explicar compara√ß√£o entre modelos

### Parte 4: Conclus√£o (2 min)
- Resumir melhorias obtidas
- Mostrar aplica√ß√£o pr√°tica na medicina
- Pr√≥ximos passos e limita√ß√µes

## üî¨ Resultados Experimentais

### Baseline vs GA Otimizado

| Modelo | Accuracy (Base) | Accuracy (GA) | Recall (Base) | Recall (GA) | Melhoria |
|--------|-----------------|---------------|---------------|-------------|----------|
| Random Forest | 0.947 | 0.956 | 0.962 | 0.981 | +0.9% |
| XGBoost | 0.956 | 0.965 | 0.962 | 0.981 | +0.9% |
| LightGBM | 0.947 | 0.956 | 0.981 | 0.981 | +0.9% |

### Explica√ß√µes Geradas

**Exemplo - Caso Maligno:**
```
DIAGN√ìSTICO: MALIGNO (C√¢ncer)

O modelo identificou padr√µes consistentes com c√¢ncer de mama maligno
com 89% de confian√ßa. As caracter√≠sticas mais relevantes incluem:
- Textura celular irregular (texture_mean: 0.23)
- √Årea das c√©lulas aumentada (area_mean: 0.19)

Pr√≥ximos passos recomendados:
1. Confirma√ß√£o atrav√©s de bi√≥psia
2. Consulta com oncologista
3. Exames complementares
```

## üõ†Ô∏è Tecnologias Utilizadas

### Core ML
- **scikit-learn**: Modelos base e m√©tricas
- **XGBoost/LightGBM**: Gradient boosting
- **SHAP**: Explicabilidade local

### Otimiza√ß√£o
- **DEAP**: Framework para algoritmos gen√©ticos
- **scipy**: Otimiza√ß√£o e estat√≠sticas

### LLMs
- **OpenAI API**: GPT-3.5/GPT-4
- **transformers**: Modelos HuggingFace
- **torch**: Backend para transformers

### Visualiza√ß√£o
- **matplotlib/seaborn**: Gr√°ficos est√°ticos
- **plotly**: Gr√°ficos interativos
- **jupyter**: Notebooks

### Testes e Deploy
- **pytest**: Testes automatizados
- **docker**: Containeriza√ß√£o
- **joblib**: Serializa√ß√£o de modelos

## ‚ö†Ô∏è Limita√ß√µes e Considera√ß√µes

### M√©dicas
- **IA como apoio**: Nunca substitui diagn√≥stico m√©dico
- **Valida√ß√£o cl√≠nica**: Necess√°ria antes do uso real
- **Falsos negativos**: Cr√≠ticos em oncologia
- **Regulamenta√ß√£o**: Aprova√ß√£o de √≥rg√£os competentes

### T√©cnicas
- **Dataset**: Limitado ao Wisconsin Breast Cancer
- **Generaliza√ß√£o**: Pode n√£o funcionar em outras popula√ß√µes
- **LLM**: Explica√ß√µes podem conter imprecis√µes
- **Computacional**: GA pode ser lento para datasets grandes

## ü§ù Contribui√ß√µes

1. Fork o projeto
2. Crie uma branch (`git checkout -b feature/nova-funcionalidade`)
3. Commit suas mudan√ßas (`git commit -am 'Adiciona nova funcionalidade'`)
4. Push para a branch (`git push origin feature/nova-funcionalidade`)
5. Abra um Pull Request

## üìÑ Licen√ßa

Este projeto √© licenciado sob a MIT License - veja o arquivo [LICENSE](LICENSE) para detalhes.

## üìû Contato

- **Desenvolvedor**: [Seu Nome]
- **Email**: [seu.email@exemplo.com]
- **LinkedIn**: [seu-linkedin]
- **Tech Challenge**: FIAP/IAD Fase 2

---

**‚ö° Projeto pronto para demonstra√ß√£o no Tech Challenge Fase 2!**

‚úÖ Algoritmos gen√©ticos implementados  
‚úÖ LLMs para explica√ß√µes autom√°ticas  
‚úÖ Notebooks interativos prontos  
‚úÖ Testes automatizados  
‚úÖ Documenta√ß√£o completa  
‚úÖ Roteiro para v√≠deo
